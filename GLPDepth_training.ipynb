{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GLPDepth_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1mt2FMifVnRj4C3B/S/+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yujunyoung1107/GLPDepth_colab/blob/main/GLPDepth_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX\n",
        "!pip install mmcv\n",
        "!pip install timm\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "rsJhR7rX_eLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH-IjX9IuIJE"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/yujunyoung1107/GLPDepth_new.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLPDepth_new/datasets/\n",
        "!unzip /content/gdrive/MyDrive/nyu_depth_v2.zip"
      ],
      "metadata": {
        "id": "T_XngYQpAoP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLPDepth_new/code/models/weights/\n",
        "!cp /content/gdrive/MyDrive/mit_b4.pth mit_bt.pth\n",
        "%cd /content/GLPDepth_new/code/"
      ],
      "metadata": {
        "id": "KVCIKKV5B8pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from tensorboardX import SummaryWriter\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from models.model import GLPDepth\n",
        "import utils.metrics as metrics\n",
        "from utils.criterion import SiLogLoss\n",
        "import utils.logging as logging\n",
        "from dataset.base_dataset import get_dataset\n",
        "from configs.train_options import TrainOptions"
      ],
      "metadata": {
        "id": "a7PRCgCnvmpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLPDepth_new/\n",
        "metric_name = ['d1', 'd2', 'd3', 'abs_rel', 'sq_rel', 'rmse', 'rmse_log',\n",
        "               'log10', 'silog']\n",
        "\n",
        "model = GLPDepth(max_depth=80, is_train=True)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    cudnn.benchmark = True\n",
        "    model = torch.nn.DataParallel(model)\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "mw3WrurVBomf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_type = 'nyudepthv2'\n",
        "data_path = '/content/GLPDepth_new/datasets/'\n",
        "\n",
        "#-----------------------hyper parameters---------------------------#\n",
        "batch_size = 6\n",
        "num_workers = 2\n",
        "lr = 1e-4\n",
        "epochs = 25\n",
        "max_dep = 10\n",
        "min_dep = 1e-3\n",
        "#------------------------------------------------------------------#\n",
        "\n",
        "dataset_kwargs = {'dataset_name': data_type, 'data_path': data_path}\n",
        "if data_type == 'nyudepthv2':\n",
        "    dataset_kwargs['crop_size'] = (448, 576)\n",
        "elif data_type == 'kitti':\n",
        "    dataset_kwargs['crop_size'] = (352, 704)\n",
        "\n",
        "train_dataset = get_dataset(**dataset_kwargs)\n",
        "val_dataset = get_dataset(**dataset_kwargs, is_train=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=num_workers, \n",
        "                                            pin_memory=True, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False,\n",
        "                                            pin_memory=True)"
      ],
      "metadata": {
        "id": "cLyDEXriki6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion_d, optimizer, device, epoch):    \n",
        "    global global_step\n",
        "    model.train()\n",
        "    depth_loss = logging.AverageMeter()\n",
        "    half_epoch = epochs // 2\n",
        "\n",
        "    with tqdm(train_loader, unit='batch') as pbar:\n",
        "        pbar.set_description(f'Epoch {epoch}')\n",
        "        for batch_idx, batch in enumerate(pbar):      \n",
        "            global_step += 1\n",
        "\n",
        "            for param_group in optimizer.param_groups:\n",
        "                if global_step < 2019 * half_epoch:\n",
        "                    current_lr = (1e-4 - 3e-5) * (global_step /\n",
        "                                                2019/half_epoch) ** 0.9 + 3e-5\n",
        "                else:\n",
        "                    current_lr = (3e-5 - 1e-4) * (global_step /\n",
        "                                                2019/half_epoch - 1) ** 0.9 + 1e-4\n",
        "                param_group['lr'] = current_lr\n",
        "\n",
        "            input_RGB = batch['image'].to(device)\n",
        "            depth_gt = batch['depth'].to(device)\n",
        "\n",
        "            preds = model(input_RGB)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss_d = criterion_d(preds['pred_d'].squeeze(), depth_gt)\n",
        "            depth_loss.update(loss_d.item(), input_RGB.size(0))\n",
        "            loss_d.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_postfix({'Loss' : depth_loss.val, 'Loss avg' : depth_loss.avg})\n",
        "\n",
        "    return loss_d\n"
      ],
      "metadata": {
        "id": "poKL_wWDKOoq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, model, criterion_d, device, epoch, max_dep, min_dep):\n",
        "    depth_loss = logging.AverageMeter()\n",
        "    model.eval()\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/gdrive//MyDrive/epoch_%02d_model.ckpt' % epoch)\n",
        "\n",
        "    result_metrics = {}\n",
        "    for metric in metric_name:\n",
        "        result_metrics[metric] = 0.0\n",
        "\n",
        "    for batch_idx, batch in enumerate(val_loader):\n",
        "        input_RGB = batch['image'].to(device)\n",
        "        depth_gt = batch['depth'].to(device)\n",
        "        filename = batch['filename'][0]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(input_RGB)\n",
        "\n",
        "        pred_d = preds['pred_d'].squeeze()\n",
        "        depth_gt = depth_gt.squeeze()\n",
        "\n",
        "        loss_d = criterion_d(preds['pred_d'].squeeze(), depth_gt)\n",
        "\n",
        "        depth_loss.update(loss_d.item(), input_RGB.size(0))\n",
        "\n",
        "        pred_crop, gt_crop = metrics.cropping_img(pred_d, max_dep, min_dep, depth_gt, data_type)\n",
        "        computed_result = metrics.eval_depth(pred_crop, gt_crop)\n",
        "\n",
        "        if save_path.split('.')[-1] == 'jpg':\n",
        "            save_path = save_path.replace('jpg', 'png')\n",
        "\n",
        "        loss_d = depth_loss.avg\n",
        "        logging.progress_bar(batch_idx, len(val_loader), epochs, epoch)\n",
        "\n",
        "        for key in result_metrics.keys():\n",
        "            result_metrics[key] += computed_result[key]\n",
        "\n",
        "    for key in result_metrics.keys():\n",
        "        result_metrics[key] = result_metrics[key] / (batch_idx + 1)\n",
        "\n",
        "    return result_metrics, loss_d"
      ],
      "metadata": {
        "id": "i221fxyxamEe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings\n",
        "criterion_d = SiLogLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "\n",
        "global global_step\n",
        "global_step = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print('\\nEpoch: %03d - %03d' % (epoch, epochs))\n",
        "    loss_train = train(train_loader, model, criterion_d, optimizer=optimizer, \n",
        "                        device=device, epoch=epoch)\n",
        "\n",
        "    \n",
        "    results_dict, loss_val = validate(val_loader, model, criterion_d, device, epoch, max_dep, min_dep)\n",
        "    result_lines = logging.display_result(results_dict)\n",
        "    print(result_lines)\n"
      ],
      "metadata": {
        "id": "RYO-K-9bIWcG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}