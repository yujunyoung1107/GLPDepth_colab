{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GLPDepth_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqI230iJZvl5I1cbga6X6g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yujunyoung1107/GLPDepth_colab/blob/main/GLPDepth_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNw_WdIVbniW"
      },
      "outputs": [],
      "source": [
        "!pip install tensorboardX\n",
        "!pip install mmcv\n",
        "!pip install timm\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yujunyoung1107/GLPDepth_new.git"
      ],
      "metadata": {
        "id": "r9w2s4Edbtd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLPDepth_new/datasets/\n",
        "!unzip /content/gdrive/MyDrive/nyu_depth_v2.zip"
      ],
      "metadata": {
        "id": "fm1ZbK83b2Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLPDepth_new/code/models/weights/\n",
        "!cp /content/gdrive/MyDrive/mit_b4.pth mit_bt.pth\n",
        "%cd /content/GLPDepth_new/code/"
      ],
      "metadata": {
        "id": "CZ_8Yc_zb3iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import utils.logging as logging\n",
        "import utils.metrics as metrics\n",
        "from models.model import GLPDepth\n",
        "from dataset.base_dataset import get_dataset"
      ],
      "metadata": {
        "id": "bEq633XCb6ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_dep = 10.0\n",
        "min_dep = 1e-3\n",
        "ckpt_dir = '/content/gdrive/MyDrive/' + 'best_model_nyu.ckpt'\n",
        "data_name = 'nyudepthv2'\n",
        "result_path = '/content/gdrive/MyDrive/result'\n",
        "heat_map = True\n",
        "depth_map = False\n",
        "\n",
        "if not isinstance(result_path, list):\n",
        "    paths = [result_path]\n",
        "for path in paths:\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "metadata": {
        "id": "WmlOC_fXdYyf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GLPDepth_new/\n",
        "metric_name = ['d1', 'd2', 'd3', 'abs_rel', 'sq_rel', 'rmse', 'rmse_log',\n",
        "               'log10', 'silog']\n",
        "\n",
        "result_metrics = {}\n",
        "for metric in metric_name:\n",
        "    result_metrics[metric] = 0.0\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = GLPDepth(max_depth=max_dep, is_train=False).to(device)\n",
        "model_weight = torch.load(ckpt_dir, map_location=torch.device('cpu'))\n",
        "if 'module' in next(iter(model_weight.items()))[0]:\n",
        "    model_weight = OrderedDict((k[7:], v) for k, v in model_weight.items())\n",
        "model.load_state_dict(model_weight)\n",
        "model.eval()\n",
        "\n",
        "dataset_kwargs = {'data_path': '/content/GLPDepth_new/datasets/', 'dataset_name': data_name, 'is_train': False}\n",
        "\n",
        "test_dataset = get_dataset(**dataset_kwargs)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "PVLhLzFNb8hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tqdm(test_loader, unit='batch') as pbar:\n",
        "    pbar.set_description(f'Test')\n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        input_RGB = batch['image'].to(device)\n",
        "        filename = batch['filename']\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(input_RGB)\n",
        "        pred_d = pred['pred_d']\n",
        "\n",
        "        depth_gt = batch['depth'].to(device)\n",
        "        pred_d, depth_gt = pred_d.squeeze(), depth_gt.squeeze()\n",
        "        pred_crop, gt_crop = metrics.cropping_img(pred_d, min_dep, max_dep, depth_gt, data_name)\n",
        "        computed_result = metrics.eval_depth(pred_crop, gt_crop)\n",
        "        for metric in metric_name:\n",
        "            result_metrics[metric] += computed_result[metric]\n",
        "\n",
        "        save_path = os.path.join(result_path, filename[0])\n",
        "\n",
        "        if depth_map and not heat_map:\n",
        "            if save_path.split('.')[-1] == 'jpg':\n",
        "                save_path = save_path.replace('jpg', 'png')\n",
        "            pred_d = pred_d.squeeze()\n",
        "            if data_name == 'nyudepthv2':\n",
        "                pred_d = pred_d.cpu().numpy() * 1000.0\n",
        "                cv2.imwrite(save_path, pred_d.astype(np.uint16),\n",
        "                            [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
        "            else:\n",
        "                pred_d = pred_d.cpu().numpy() * 256.0\n",
        "                cv2.imwrite(save_path, pred_d.astype(np.uint16),\n",
        "                            [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
        "            \n",
        "        if heat_map and not depth_map:\n",
        "            pred_d_numpy = pred_d.squeeze().cpu().numpy()\n",
        "            pred_d_numpy = (pred_d_numpy / pred_d_numpy.max()) * 255\n",
        "            pred_d_numpy = pred_d_numpy.astype(np.uint8)\n",
        "            pred_d_color = cv2.applyColorMap(pred_d_numpy, cv2.COLORMAP_RAINBOW)\n",
        "            cv2.imwrite(save_path, pred_d_color)\n",
        "\n",
        "    for key in result_metrics.keys():\n",
        "        result_metrics[key] = result_metrics[key] / (batch_idx + 1)\n",
        "    display_result = logging.display_result(result_metrics)\n",
        "    print(display_result)\n",
        "\n",
        "    print(\"Done\")"
      ],
      "metadata": {
        "id": "S9SXUHPPhss_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}